{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3778898",
   "metadata": {},
   "source": [
    "# [STARTER] Exercise - Building an Agentic RAG System\n",
    "\n",
    "In this exercise, you will build an Agentic RAG (Retrieval-Augmented Generation) system that \n",
    "combines the power of AI agents with traditional RAG pipelines. You'll create an agent that \n",
    "can decide when and how to retrieve information from different sources, including vector \n",
    "databases, web search, and other tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e57bd8",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Your challenge is to create an Agentic RAG system that can:\n",
    "\n",
    "- Build a RAG pipeline as a tool that can be used by the agent\n",
    "- Create an agent that can decide which tool to use based on the query\n",
    "- Handle different types of queries intelligently\n",
    "- Combine information from multiple sources when needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa44fc7",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c02f4415-346a-4543-8100-15ffb78dc102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "nb_dir = Path(__file__).parent if \"__file__\" in globals() else Path.cwd()\n",
    "parent = nb_dir.parent  # points to 03-building-agents\n",
    "if str(parent) not in sys.path:\n",
    "    sys.path.insert(0, str(parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2023814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08286c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from lib.agents import Agent\n",
    "from lib.llm import LLM\n",
    "from lib.state_machine import Run\n",
    "from lib.messages import BaseMessage\n",
    "from lib.tooling import tool\n",
    "from lib.vector_db import VectorStoreManager, CorpusLoaderService\n",
    "from lib.rag import RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4002bf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34fff998",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf20cb",
   "metadata": {},
   "source": [
    "## Load data to Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ff19b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreManager():<chromadb.api.client.Client object at 0x11da9c050>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = VectorStoreManager(OPENAI_API_KEY)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de2f3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_service = CorpusLoaderService(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92f0f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_llm = LLM(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23ec93e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStore `games_market` ready!\n",
      "Pages from `TheGamingIndustry2024.pdf` added!\n"
     ]
    }
   ],
   "source": [
    "games_market_rag = RAG(\n",
    "    llm=rag_llm,\n",
    "    vector_store=loader_service.load_pdf(\n",
    "        store_name=\"games_market\",\n",
    "        pdf_path=\"TheGamingIndustry2024.pdf\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea37488f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: augment\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "The state of virtual reality (VR) in 2024 is characterized by its significant impact on the gaming industry, allowing players to immerse themselves in realistic and interactive digital environments. VR technology is enhancing gaming experiences by providing high-fidelity graphics, intuitive controls, and immersive audio. Games like \"Half-Life: Alyx\" exemplify this trend, offering players a visceral experience where their decisions have meaningful consequences. Additionally, VR is being utilized beyond gaming, with applications in education, therapy, and mental health, showcasing its transformative potential in various fields. Overall, VR is a key technological innovation that is reshaping how players engage with digital worlds.\n"
     ]
    }
   ],
   "source": [
    "result:Run = games_market_rag.invoke(\n",
    "    \"What's the  state of virtual reality\"\n",
    ")\n",
    "print(result.get_final_state()[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb431a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStore `electric_vehicles` ready!\n",
      "Pages from `GlobalEVOutlook2025.pdf` added!\n"
     ]
    }
   ],
   "source": [
    "electric_vehicles_rag = RAG(\n",
    "    llm=rag_llm,\n",
    "    vector_store=loader_service.load_pdf(\n",
    "        store_name=\"electric_vehicles\",\n",
    "        pdf_path=\"GlobalEVOutlook2025.pdf\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b02c5f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: augment\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "In 2024, Brazil had nearly 125,000 electric car sales, which represented a market share of 6.5%.\n"
     ]
    }
   ],
   "source": [
    "result:Run = electric_vehicles_rag.invoke(\"What was the number of electric car sales and their market share in Brazil in 2024?\")\n",
    "print(result.get_final_state()[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8accfccd",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "In a simple form, Agentic RAG can act like a router, choosing between multiple external sources to retrieve relevant information. These sources aren't limited to databases, they can also include tools like web search or APIs for services such as Slack or email.\n",
    "\n",
    "In this case it will choose between two collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "654a3cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_global_ev_collection(query: str) -> dict:\n",
    "    \"\"\"Query the 'electric_vehicles' vector store and return a structured result.\n",
    "\n",
    "    Inputs:\n",
    "        query (str): Natural-language question.\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "          \"collection\": \"electric_vehicles\",\n",
    "          \"answer\": str,              # \"\" if unknown\n",
    "          \"status\": \"ok\"|\"no_context\" # hints to the agent\n",
    "        }\n",
    "    \"\"\"\n",
    "    result: Run = electric_vehicles_rag.invoke(query)\n",
    "    ans = (result.get_final_state() or {}).get(\"answer\") or \"\"\n",
    "    status = \"ok\" if ans and ans.lower() != \"i don't know.\" else \"no_context\"\n",
    "    return {\"collection\": \"electric_vehicles\", \"answer\": ans, \"status\": status}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f93dad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool\n",
    "def search_games_market_report_collection(query: str) -> dict:\n",
    "    \"\"\"Query the 'games_market' vector store and return a structured result.\n",
    "\n",
    "    Inputs:\n",
    "        query (str): Natural-language question.\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "          \"collection\": \"games_market\",\n",
    "          \"answer\": str,\n",
    "          \"status\": \"ok\"|\"no_context\"\n",
    "        }\n",
    "    \"\"\"\n",
    "    result: Run = games_market_rag.invoke(query)\n",
    "    ans = (result.get_final_state() or {}).get(\"answer\") or \"\"\n",
    "    status = \"ok\" if ans and ans.lower() != \"i don't know.\" else \"no_context\"\n",
    "    return {\"collection\": \"games_market\", \"answer\": ans, \"status\": status}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1a4f2fa-c830-46e1-b240-1d342df2676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_instructions_with_tools(tools) -> str:\n",
    "    lines = []\n",
    "    for t in tools:\n",
    "        sig = str(getattr(t, \"signature\", \"\"))\n",
    "        desc = getattr(t, \"description\", \"\") or \"\"\n",
    "        lines.append(f\"- {t.name}{sig}: {desc}\")\n",
    "    catalog = \"\\n\".join(lines)\n",
    "\n",
    "    return (\n",
    "        \"You are an Agentic RAG assistant that selects the best tool for each query.\\n\"\n",
    "        \"\\n\"\n",
    "        \"Action policy:\\n\"\n",
    "        \"- Prefer the EV collection for EV questions; the games collection for gaming/VR questions.\\n\"\n",
    "        \"- When a tool returns a structured result with status == 'no_context' or answer == '' or 'I don't know.',\\n\"\n",
    "        \"  you must immediately try the other tool with the same query (or a refined query).\\n\"\n",
    "        \"- Keep answers concise. When you use a tool, use the tool’s answer field directly.\\n\"\n",
    "        \"\\n\"\n",
    "        \"Tools you can use:\\n\"\n",
    "        f\"{catalog}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55545fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_global_ev_collection, search_games_market_report_collection]\n",
    "instructions = build_instructions_with_tools(tools)\n",
    "\n",
    "agentic_rag = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    tools=tools,\n",
    "    instructions=instructions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b249160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_messages(messages: List[BaseMessage]):\n",
    "    for m in messages: \n",
    "        print(f\" -> (role = {m.role}, content = {m.content}, tool_calls = {getattr(m, 'tool_calls', None)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab35308",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "456b76fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: augment\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: augment\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "\n",
      "Messages from run 1:\n",
      " -> (role = system, content = You are an Agentic RAG assistant that selects the best tool for each query.\n",
      "\n",
      "Action policy:\n",
      "- Prefer the EV collection for EV questions; the games collection for gaming/VR questions.\n",
      "- When a tool returns a structured result with status == 'no_context' or answer == '' or 'I don't know.',\n",
      "  you must immediately try the other tool with the same query (or a refined query).\n",
      "- Keep answers concise. When you use a tool, use the tool’s answer field directly.\n",
      "\n",
      "Tools you can use:\n",
      "- search_global_ev_collection(query: str) -> dict: Query the 'electric_vehicles' vector store and return a structured result.\n",
      "\n",
      "Inputs:\n",
      "    query (str): Natural-language question.\n",
      "\n",
      "Returns:\n",
      "    dict: {\n",
      "      \"collection\": \"electric_vehicles\",\n",
      "      \"answer\": str,              # \"\" if unknown\n",
      "      \"status\": \"ok\"|\"no_context\" # hints to the agent\n",
      "    }\n",
      "- search_games_market_report_collection(query: str) -> dict: Query the 'games_market' vector store and return a structured result.\n",
      "\n",
      "Inputs:\n",
      "    query (str): Natural-language question.\n",
      "\n",
      "Returns:\n",
      "    dict: {\n",
      "      \"collection\": \"games_market\",\n",
      "      \"answer\": str,\n",
      "      \"status\": \"ok\"|\"no_context\"\n",
      "    }\n",
      ", tool_calls = None)\n",
      " -> (role = user, content = Who won the 2025 Oscar for International Movie?, tool_calls = None)\n",
      " -> (role = assistant, content = None, tool_calls = [ChatCompletionMessageToolCall(id='call_BzLGxEPIFBYIVyi9zE97qq01', function=Function(arguments='{\"query\": \"2025 Oscar for International Movie winner\"}', name='search_global_ev_collection'), type='function'), ChatCompletionMessageToolCall(id='call_rVsFa0YBw6DJMlFNSHzGys1O', function=Function(arguments='{\"query\": \"2025 Oscar for International Movie winner\"}', name='search_games_market_report_collection'), type='function')])\n",
      " -> (role = tool, content = {\"collection\": \"electric_vehicles\", \"answer\": \"I don't know.\", \"status\": \"no_context\"}, tool_calls = None)\n",
      " -> (role = tool, content = {\"collection\": \"games_market\", \"answer\": \"I don't know.\", \"status\": \"no_context\"}, tool_calls = None)\n",
      " -> (role = assistant, content = I don't have information on the winner of the 2025 Oscar for International Movie., tool_calls = None)\n"
     ]
    }
   ],
   "source": [
    "run_1 = agentic_rag.invoke(\n",
    "    query=\"Who won the 2025 Oscar for International Movie?\", \n",
    "    session_id=\"oscar\",\n",
    ")\n",
    "\n",
    "print(\"\\nMessages from run 1:\")\n",
    "messages = run_1.get_final_state()[\"messages\"]\n",
    "print_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3831d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: augment\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "\n",
      "Messages from run 2:\n",
      " -> (role = system, content = You are an Agentic RAG assistant that selects the best tool for each query.\n",
      "\n",
      "Action policy:\n",
      "- Prefer the EV collection for EV questions; the games collection for gaming/VR questions.\n",
      "- When a tool returns a structured result with status == 'no_context' or answer == '' or 'I don't know.',\n",
      "  you must immediately try the other tool with the same query (or a refined query).\n",
      "- Keep answers concise. When you use a tool, use the tool’s answer field directly.\n",
      "\n",
      "Tools you can use:\n",
      "- search_global_ev_collection(query: str) -> dict: Query the 'electric_vehicles' vector store and return a structured result.\n",
      "\n",
      "Inputs:\n",
      "    query (str): Natural-language question.\n",
      "\n",
      "Returns:\n",
      "    dict: {\n",
      "      \"collection\": \"electric_vehicles\",\n",
      "      \"answer\": str,              # \"\" if unknown\n",
      "      \"status\": \"ok\"|\"no_context\" # hints to the agent\n",
      "    }\n",
      "- search_games_market_report_collection(query: str) -> dict: Query the 'games_market' vector store and return a structured result.\n",
      "\n",
      "Inputs:\n",
      "    query (str): Natural-language question.\n",
      "\n",
      "Returns:\n",
      "    dict: {\n",
      "      \"collection\": \"games_market\",\n",
      "      \"answer\": str,\n",
      "      \"status\": \"ok\"|\"no_context\"\n",
      "    }\n",
      ", tool_calls = None)\n",
      " -> (role = user, content = Which two countries accounted for most of the electric car exports from the Asia Pacific region (excluding China) in 2024?, tool_calls = None)\n",
      " -> (role = assistant, content = None, tool_calls = [ChatCompletionMessageToolCall(id='call_U0YOvPr59PDz0dfoLVJWTQSG', function=Function(arguments='{\"query\":\"electric car exports Asia Pacific region 2024 excluding China\"}', name='search_global_ev_collection'), type='function')])\n",
      " -> (role = tool, content = {\"collection\": \"electric_vehicles\", \"answer\": \"In 2024, Japan and Korea accounted for the majority of the nearly 640,000 electric cars exported from the Asia Pacific region, excluding China, marking an increase of 15% from 2023. The United States was the main destination for these exports, making up more than a quarter of the production from the region. Europe was the second-largest destination, importing another quarter of the region's electric car production.\", \"status\": \"ok\"}, tool_calls = None)\n",
      " -> (role = assistant, content = In 2024, Japan and Korea accounted for the majority of the nearly 640,000 electric cars exported from the Asia Pacific region, excluding China., tool_calls = None)\n"
     ]
    }
   ],
   "source": [
    "run_2 = agentic_rag.invoke(\n",
    "    query= (\n",
    "        \"Which two countries accounted for most of the electric car exports from \" \n",
    "        \"the Asia Pacific region (excluding China) in 2024?\"\n",
    "    ),\n",
    "    session_id=\"electric_car\",\n",
    ")\n",
    "\n",
    "print(\"\\nMessages from run 2:\")\n",
    "messages = run_2.get_final_state()[\"messages\"]\n",
    "print_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25698ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: augment\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "\n",
      "Messages from run 3:\n",
      " -> (role = system, content = You are an Agentic RAG assistant that selects the best tool for each query.\n",
      "\n",
      "Action policy:\n",
      "- Prefer the EV collection for EV questions; the games collection for gaming/VR questions.\n",
      "- When a tool returns a structured result with status == 'no_context' or answer == '' or 'I don't know.',\n",
      "  you must immediately try the other tool with the same query (or a refined query).\n",
      "- Keep answers concise. When you use a tool, use the tool’s answer field directly.\n",
      "\n",
      "Tools you can use:\n",
      "- search_global_ev_collection(query: str) -> dict: Query the 'electric_vehicles' vector store and return a structured result.\n",
      "\n",
      "Inputs:\n",
      "    query (str): Natural-language question.\n",
      "\n",
      "Returns:\n",
      "    dict: {\n",
      "      \"collection\": \"electric_vehicles\",\n",
      "      \"answer\": str,              # \"\" if unknown\n",
      "      \"status\": \"ok\"|\"no_context\" # hints to the agent\n",
      "    }\n",
      "- search_games_market_report_collection(query: str) -> dict: Query the 'games_market' vector store and return a structured result.\n",
      "\n",
      "Inputs:\n",
      "    query (str): Natural-language question.\n",
      "\n",
      "Returns:\n",
      "    dict: {\n",
      "      \"collection\": \"games_market\",\n",
      "      \"answer\": str,\n",
      "      \"status\": \"ok\"|\"no_context\"\n",
      "    }\n",
      ", tool_calls = None)\n",
      " -> (role = user, content = Why is generative AI seen more as an accelerator than a replacement in game development?, tool_calls = None)\n",
      " -> (role = assistant, content = None, tool_calls = [ChatCompletionMessageToolCall(id='call_2vIPksxNNKAIlYa4EJZGixv6', function=Function(arguments='{\"query\":\"Why is generative AI seen more as an accelerator than a replacement in game development?\"}', name='search_games_market_report_collection'), type='function')])\n",
      " -> (role = tool, content = {\"collection\": \"games_market\", \"answer\": \"Generative AI is seen more as an accelerator than a replacement in game development because it enhances functionality and streamlines processes rather than completely taking over the creative aspects of game design. AI assists in automating complex tasks and simulating intelligent behavior, which allows developers to focus on more innovative and creative elements of game development. For example, AI can help create dynamic and responsive non-player characters (NPCs) that enhance realism and depth in gameplay, but it does not replace the need for human creativity and oversight in crafting engaging game experiences.\", \"status\": \"ok\"}, tool_calls = None)\n",
      " -> (role = assistant, content = Generative AI is viewed as an accelerator in game development because it enhances functionality and streamlines processes without replacing the creative aspects of game design. It automates complex tasks, allowing developers to focus on innovation. For instance, AI can create dynamic non-player characters (NPCs) that add realism, but it doesn't substitute for human creativity in crafting engaging experiences., tool_calls = None)\n"
     ]
    }
   ],
   "source": [
    "run_3 = agentic_rag.invoke(\n",
    "    query= (\n",
    "        \"Why is generative AI seen more as an accelerator than a replacement in game development?\"\n",
    "    ),\n",
    "    session_id=\"games\",\n",
    ")\n",
    "\n",
    "print(\"\\nMessages from run 3:\")\n",
    "messages = run_3.get_final_state()[\"messages\"]\n",
    "print_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff934c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d724e28-55ff-4605-b309-c8130fde7314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
