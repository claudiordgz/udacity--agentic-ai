{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9baf30a2",
   "metadata": {},
   "source": [
    "# [STARTER] Exercise - Building a Multi-Step State Machine Agent\n",
    "\n",
    "In this exercise, you will build an agent that manages a multi-step workflow using a state machine. You’ll define a custom state schema, implement step logic, connect steps (including conditional routing and loops), and run the workflow to process user input through several transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb9056",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You have learned how to use a state machine to manage workflow steps and transitions. Now, your challenge is to:\n",
    "\n",
    "- Define a state schema with multiple fields (e.g., user_query, instructions, messages, current_tool_calls).\n",
    "- Implement at least three step functions:\n",
    "    - Prepare Messages: Assemble the conversation history and any required context for the LLM.\n",
    "    - LLM: Call the language model to generate a response or tool call.\n",
    "    - Tools: Execute any required tool calls and update the state with results.\n",
    "- Connect steps to form a workflow, including:\n",
    "    - Entrypoint and Termination steps to start and end the workflow.\n",
    "    - Conditional routing: If the LLM response includes tool calls, route to the Tools step; otherwise, proceed to Termination.\n",
    "    - Looping: After executing tools, return to the LLM step to continue the workflow until there are no more tool calls.\n",
    "- Run your state machine with a sample input and inspect the state transitions and snapshots to understand how your agent processes a task step by step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c0e231",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97afd25b-3c6a-4aa7-b990-a4f05fe235a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "nb_dir = Path(__file__).parent if \"__file__\" in globals() else Path.cwd()\n",
    "parent = nb_dir.parent  # points to 03-building-agents\n",
    "if str(parent) not in sys.path:\n",
    "    sys.path.insert(0, str(parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42ccb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Optional, Union\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination, Run\n",
    "from lib.llm import LLM\n",
    "from lib.messages import AIMessage, UserMessage, SystemMessage, ToolMessage\n",
    "from lib.tooling import Tool, ToolCall, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8686cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41de723",
   "metadata": {},
   "source": [
    "## Define a State Schema\n",
    "\n",
    "Create a TypedDict to represent the agent’s state, including fields for the user query, instructions, message history, and any pending tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99605c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the AgentState TypedDict\n",
    "# Include fields for user_query, instructions, messages, and current_tool_calls\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    Schema for the agent's state while processing a query.\n",
    "\n",
    "    Attributes:\n",
    "        user_query (str): The raw query text from the user.\n",
    "        instructions (str): Any system or guiding instructions for the agent.\n",
    "        messages (List[dict]): Conversation history, usually messages with role/content.\n",
    "        current_tool_calls (Optional[List[ToolCall]]): Tools the agent is currently invoking,\n",
    "            with args and call IDs.\n",
    "        \n",
    "    \"\"\"\n",
    "    user_query: str\n",
    "    instructions: str\n",
    "    messages: List[dict]\n",
    "    current_tool_calls: Optional[List[ToolCall]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da75109",
   "metadata": {},
   "source": [
    "## Define the Tools you will use\n",
    "\n",
    "Feel free to modify to add any tool you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1d171e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional\n",
    "import math\n",
    "\n",
    "GAMES_DATA: List[Dict[str, Any]] = [\n",
    "    {\"Game\": \"The Legend of Zelda: Breath of the Wild\", \"Platform\": \"Switch\", \"Score\": 98},\n",
    "    {\"Game\": \"Super Mario Odyssey\", \"Platform\": \"Switch\", \"Score\": 97},\n",
    "    {\"Game\": \"Metroid Prime\", \"Platform\": \"GameCube\", \"Score\": 97},\n",
    "    {\"Game\": \"Super Smash Bros. Brawl\", \"Platform\": \"Wii\", \"Score\": 93},\n",
    "    {\"Game\": \"Mario Kart 8 Deluxe\", \"Platform\": \"Switch\", \"Score\": 92},\n",
    "    {\"Game\": \"Fire Emblem: Awakening\", \"Platform\": \"3DS\", \"Score\": 92},\n",
    "    {\"Game\": \"Donkey Kong Country Returns\", \"Platform\": \"Wii\", \"Score\": 87},\n",
    "    {\"Game\": \"Luigi's Mansion 3\", \"Platform\": \"Switch\", \"Score\": 86},\n",
    "    {\"Game\": \"Pikmin 3\", \"Platform\": \"Wii U\", \"Score\": 85},\n",
    "    {\"Game\": \"Animal Crossing: New Leaf\", \"Platform\": \"3DS\", \"Score\": 88}\n",
    "]\n",
    "\n",
    "@tool\n",
    "def get_games(num_games:int=1, top:bool=True) -> str:\n",
    "    \"\"\"\n",
    "    Returns the top or bottom N games with highest or lowest scores.    \n",
    "    args:\n",
    "        num_games (int): Number of games to return (default is 1)\n",
    "        top (bool): If True, return top games, otherwise return bottom (default is True)\n",
    "    \"\"\"\n",
    "    # Sort the games list by Score\n",
    "    # If top is True, descending order\n",
    "    sorted_games = sorted(GAMES_DATA, key=lambda x: x['Score'], reverse=top)\n",
    "    \n",
    "    # Return the N games\n",
    "    return sorted_games[:num_games]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c715bfca-15ec-41cb-89bc-1b72dbd10299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _median(nums: List[float]) -> float:\n",
    "    s = sorted(nums)\n",
    "    n = len(s)\n",
    "    mid = n // 2\n",
    "    if n % 2 == 1:\n",
    "        return float(s[mid])\n",
    "    return (s[mid - 1] + s[mid]) / 2.0\n",
    "\n",
    "def _stdev(nums: List[float]) -> float:\n",
    "    n = len(nums)\n",
    "    if n <= 1:\n",
    "        return 0.0\n",
    "    mean = sum(nums) / n\n",
    "    var = sum((x - mean) ** 2 for x in nums) / n  # population stdev\n",
    "    return math.sqrt(var)\n",
    "\n",
    "@tool\n",
    "def get_game_stats(group_by: Optional[str] = \"Platform\",\n",
    "                   bucket_size: Optional[int] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Calculate score statistics and distributions for the games dataset.\n",
    "\n",
    "    args:\n",
    "        group_by (str | None): Field to group by for a categorical distribution\n",
    "                               (e.g., \"Platform\"). Use None to skip grouping.\n",
    "        bucket_size (int | None): If provided, create a histogram of scores with this\n",
    "                                  bucket width (e.g., 5 -> 80-84, 85-89, ...).\n",
    "\n",
    "    returns:\n",
    "        dict: {\n",
    "          \"count\": int,\n",
    "          \"score\": {\"avg\": float, \"median\": float, \"min\": int, \"max\": int, \"stdev\": float},\n",
    "          \"distribution\": {<group_value>: {\"count\": int, \"avg\": float}} | null,\n",
    "          \"score_histogram\": { \"<lo>-<hi>\": int } | null\n",
    "        }\n",
    "    \"\"\"\n",
    "    data = GAMES_DATA\n",
    "    scores = [row[\"Score\"] for row in data]\n",
    "    n = len(scores)\n",
    "\n",
    "    overall = {\n",
    "        \"count\": n,\n",
    "        \"score\": {\n",
    "            \"avg\": sum(scores) / n if n else 0.0,\n",
    "            \"median\": _median(scores) if n else 0.0,\n",
    "            \"min\": min(scores) if n else 0,\n",
    "            \"max\": max(scores) if n else 0,\n",
    "            \"stdev\": _stdev(scores) if n else 0.0,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Categorical distribution (e.g., by Platform)\n",
    "    distribution: Optional[Dict[str, Dict[str, float]]] = None\n",
    "    if group_by:\n",
    "        buckets: Dict[str, List[int]] = {}\n",
    "        for row in data:\n",
    "            key = str(row.get(group_by, \"Unknown\"))\n",
    "            buckets.setdefault(key, []).append(row[\"Score\"])\n",
    "        distribution = {\n",
    "            k: {\"count\": len(v), \"avg\": (sum(v) / len(v) if v else 0.0)}\n",
    "            for k, v in buckets.items()\n",
    "        }\n",
    "\n",
    "    # Score histogram with fixed bucket width\n",
    "    score_histogram: Optional[Dict[str, int]] = None\n",
    "    if bucket_size and bucket_size > 0 and n:\n",
    "        lo = (min(scores) // bucket_size) * bucket_size\n",
    "        hi = (max(scores) // bucket_size) * bucket_size\n",
    "        bins: Dict[str, int] = {}\n",
    "        for s in scores:\n",
    "            b_lo = (s // bucket_size) * bucket_size\n",
    "            b_hi = b_lo + (bucket_size - 1)\n",
    "            label = f\"{int(b_lo)}-{int(b_hi)}\"\n",
    "            bins[label] = bins.get(label, 0) + 1\n",
    "        # Ensure empty bins between lo..hi exist (optional but nice)\n",
    "        cur = lo\n",
    "        while cur <= hi:\n",
    "            label = f\"{int(cur)}-{int(cur + bucket_size - 1)}\"\n",
    "            bins.setdefault(label, 0)\n",
    "            cur += bucket_size\n",
    "        # Sort labels numerically\n",
    "        score_histogram = {k: bins[k] for k in sorted(bins.keys(), key=lambda x: int(x.split(\"-\")[0]))}\n",
    "\n",
    "    overall[\"distribution\"] = distribution\n",
    "    overall[\"score_histogram\"] = score_histogram\n",
    "    return overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a07c2679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add as many tools as you want\n",
    "# Use the @tool decorator and implement functions like get_games\n",
    "\n",
    "tools = [get_games, get_game_stats]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052be6c2",
   "metadata": {},
   "source": [
    "## Create the Steps\n",
    "\n",
    "Write functions for each step in your workflow:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd86828",
   "metadata": {},
   "source": [
    "**Prepare Messages**: Build the message list for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6341e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the prepare_messages_step function\n",
    "# This function should take AgentState and return AgentState with prepared messages\n",
    "# Use instructions to create the SystemMessage and user_query to create UserMessage\n",
    "# Then return AgentState with the messages list with the SystemMessage and UserMessage\n",
    "\n",
    "def prepare_messages_step(state: AgentState) -> AgentState:\n",
    "    messages = [\n",
    "        SystemMessage(content=state[\"instructions\"]),\n",
    "        UserMessage(content=state[\"user_query\"])\n",
    "    ]\n",
    "    return { \"messages\": messages }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ce1ea",
   "metadata": {},
   "source": [
    "**LLM Step**: Call the language model and check for tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dbf3396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the llm_step function\n",
    "# This function should process the state through an LLM and handle tool calls\n",
    "# It should append the AIMessage to the messages list \n",
    "# and return the State with the messages and the current_tool_calls.\n",
    "# You can get the tool_calls object accessing it from the llm invoke response: `response.tool_calls`\n",
    "\n",
    "def llm_step(state: AgentState) -> AgentState:\n",
    "    llm = LLM(\n",
    "        tools=tools\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    tool_calls = response.tool_calls if response.tool_calls else None\n",
    "\n",
    "    ai_message = AIMessage(content=response.content, tool_calls=tool_calls)\n",
    "\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [ai_message],\n",
    "        \"current_tool_calls\": tool_calls\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "727567e9-2f4e-4d45-b5f0-dd7cf0d98eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "def pretty_print_messages(messages):\n",
    "    for m in messages:\n",
    "        role = getattr(m, \"role\", m.__class__.__name__.replace(\"Message\",\"\").lower())\n",
    "        # Tool call announcement from the AI\n",
    "        tool_calls = getattr(m, \"tool_calls\", None)\n",
    "        if tool_calls:\n",
    "            print(f\"{role.upper()}: [tool_calls]\")\n",
    "            for tc in tool_calls:\n",
    "                print(f\"  -> call_id={tc.id} func={tc.function.name} args={tc.function.arguments}\")\n",
    "            print(\"-\" * 80)\n",
    "            continue\n",
    "\n",
    "        # Tool results\n",
    "        name = getattr(m, \"name\", None)\n",
    "        if name:  # ToolMessage\n",
    "            print(f\"TOOL[{name}]:\")\n",
    "            content = getattr(m, \"content\", \"\")\n",
    "            try:\n",
    "                payload = json.loads(content)\n",
    "            except Exception:\n",
    "                payload = content\n",
    "            pprint(payload, width=100, compact=True)\n",
    "            print(\"-\" * 80)\n",
    "            continue\n",
    "\n",
    "        # Regular assistant/user/system message\n",
    "        print(f\"{role.upper()}:\")\n",
    "        pprint(getattr(m, \"content\", None), width=100)\n",
    "        print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5288ecd4",
   "metadata": {},
   "source": [
    "**Tool Step**: Execute any tool calls and update the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32124e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the tool_step function\n",
    "# This function should execute any pending tool calls and update the state\n",
    "# Make sure to iterate over tool_calls object\n",
    "# Extend the messages list from the state with all ToolMessages\n",
    "# Don't forget to set current_tool_calls to None\n",
    "\n",
    "def tool_step(state: AgentState) -> AgentState:\n",
    "    tool_calls = state[\"current_tool_calls\"] or []\n",
    "    tool_messages = []\n",
    "\n",
    "    for call in tool_calls:\n",
    "        function_name = call.function.name\n",
    "        function_args = json.loads(call.function.arguments)\n",
    "        tool_call_id = call.id\n",
    "        tool = next((t for t in tools if t.name == function_name), None)\n",
    "        if tool:\n",
    "            result = tool(**function_args)\n",
    "            tool_messages.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(result),\n",
    "                    tool_call_id=tool_call_id,\n",
    "                    name=function_name,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + tool_messages,\n",
    "        \"current_tool_calls\": None\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aaddee",
   "metadata": {},
   "source": [
    "## Build and Connect the State Machine\n",
    "\n",
    "Add your steps to the state machine, and connect them with transitions. Use conditional routing to decide whether to call tools or terminate, and loop as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58ca0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize the StateMachine with the AgentState\n",
    "workflow = StateMachine(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d52f8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = EntryPoint[AgentState]()\n",
    "message_prep = Step[AgentState](\"message_prep\", prepare_messages_step)\n",
    "llm_processor = Step[AgentState](\"llm_processor\", llm_step)\n",
    "tool_executor = Step[AgentState](\"tool_executor\", tool_step)\n",
    "termination = Termination[AgentState]()\n",
    "\n",
    "# TODO: Add all the steps to the workflow using workflow.add_steps   \n",
    "workflow.add_steps([\n",
    "    entry,\n",
    "    message_prep,\n",
    "    llm_processor,\n",
    "    tool_executor,\n",
    "    termination\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ae5a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transitions\n",
    "workflow.connect(entry, message_prep)\n",
    "workflow.connect(message_prep, llm_processor)\n",
    "\n",
    "# Transition based on whether there are tool calls\n",
    "def check_tool_calls(state: AgentState) -> Union[Step[AgentState], str]:\n",
    "    \"\"\"Transition logic: Check if there are tool calls\"\"\"\n",
    "    if state.get(\"current_tool_calls\"):\n",
    "        return tool_executor\n",
    "    return termination\n",
    "\n",
    "# Routing: If tool calls -> tool_executor\n",
    "workflow.connect(\n",
    "    source=llm_processor, \n",
    "    targets=[tool_executor, termination], \n",
    "    condition=check_tool_calls\n",
    ")\n",
    "\n",
    "# Looping: Go back to llm after tool execution\n",
    "workflow.connect(\n",
    "    source=tool_executor, \n",
    "    targets=llm_processor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffeb8b6",
   "metadata": {},
   "source": [
    "## Run the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df4facbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state: AgentState = {\n",
    "    \"user_query\": \"What's the best game in the dataset?\",\n",
    "    \"instructions\": \"You can bring insights about a game dataset based on users questions\",\n",
    "    \"messages\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8174c911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n"
     ]
    }
   ],
   "source": [
    "run_object = workflow.run(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44f2c752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(role='system', content='You can bring insights about a game dataset based on users questions'),\n",
       " UserMessage(role='user', content=\"What's the best game in the dataset?\"),\n",
       " AIMessage(role='assistant', content=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ytSsvp1EjTHjj9B4EWw6NzlW', function=Function(arguments='{\"num_games\":1,\"top\":true}', name='get_games'), type='function')]),\n",
       " ToolMessage(role='tool', content='[{\"Game\": \"The Legend of Zelda: Breath of the Wild\", \"Platform\": \"Switch\", \"Score\": 98}]', tool_call_id='call_ytSsvp1EjTHjj9B4EWw6NzlW', name='get_games'),\n",
       " AIMessage(role='assistant', content='The best game in the dataset is **The Legend of Zelda: Breath of the Wild** for the **Switch**, with a score of **98**.', tool_calls=None)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_object.get_final_state()[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "854d4764-7c73-4072-9891-597613a2ba24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM:\n",
      "'You can bring insights about a game dataset based on users questions'\n",
      "--------------------------------------------------------------------------------\n",
      "USER:\n",
      "\"What's the best game in the dataset?\"\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT: [tool_calls]\n",
      "  -> call_id=call_ytSsvp1EjTHjj9B4EWw6NzlW func=get_games args={\"num_games\":1,\"top\":true}\n",
      "--------------------------------------------------------------------------------\n",
      "TOOL[get_games]:\n",
      "[{'Game': 'The Legend of Zelda: Breath of the Wild', 'Platform': 'Switch', 'Score': 98}]\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT:\n",
      "('The best game in the dataset is **The Legend of Zelda: Breath of the Wild** for the **Switch**, '\n",
      " 'with a score of **98**.')\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pretty_print_messages(run_object.get_final_state()[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57846326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(role='system', content='You can bring insights about a game dataset based on users questions'),\n",
       " UserMessage(role='user', content='Please list the bottom 2 games by score.'),\n",
       " AIMessage(role='assistant', content=None, tool_calls=[ChatCompletionMessageToolCall(id='call_8Uen2eYez6lPcFcxby2lizAe', function=Function(arguments='{\"num_games\":2,\"top\":false}', name='get_games'), type='function')]),\n",
       " ToolMessage(role='tool', content='[{\"Game\": \"Pikmin 3\", \"Platform\": \"Wii U\", \"Score\": 85}, {\"Game\": \"Luigi\\'s Mansion 3\", \"Platform\": \"Switch\", \"Score\": 86}]', tool_call_id='call_8Uen2eYez6lPcFcxby2lizAe', name='get_games'),\n",
       " AIMessage(role='assistant', content=\"The bottom 2 games by score are:\\n\\n1. **Pikmin 3** (Platform: Wii U) - Score: 85\\n2. **Luigi's Mansion 3** (Platform: Switch) - Score: 86\", tool_calls=None)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Create more test cases\n",
    "# Initialize the state and run the workflow with another sample query\n",
    "# Additional test cases\n",
    "# 1) Request bottom 2 games by score\n",
    "initial_state_2: AgentState = {\n",
    "    \"user_query\": \"Please list the bottom 2 games by score.\",\n",
    "    \"instructions\": \"You can bring insights about a game dataset based on users questions\",\n",
    "    \"messages\": [],\n",
    "}\n",
    "run_object_2 = workflow.run(initial_state_2)\n",
    "run_object_2.get_final_state()[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b328b585-db17-4f77-98d8-881da1a1ed0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM:\n",
      "'You can bring insights about a game dataset based on users questions'\n",
      "--------------------------------------------------------------------------------\n",
      "USER:\n",
      "'Please list the bottom 2 games by score.'\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT: [tool_calls]\n",
      "  -> call_id=call_8Uen2eYez6lPcFcxby2lizAe func=get_games args={\"num_games\":2,\"top\":false}\n",
      "--------------------------------------------------------------------------------\n",
      "TOOL[get_games]:\n",
      "[{'Game': 'Pikmin 3', 'Platform': 'Wii U', 'Score': 85},\n",
      " {'Game': \"Luigi's Mansion 3\", 'Platform': 'Switch', 'Score': 86}]\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT:\n",
      "('The bottom 2 games by score are:\\n'\n",
      " '\\n'\n",
      " '1. **Pikmin 3** (Platform: Wii U) - Score: 85\\n'\n",
      " \"2. **Luigi's Mansion 3** (Platform: Switch) - Score: 86\")\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pretty_print_messages(run_object_2.get_final_state()[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56524c7d-232f-4b76-b30e-a231bdf5f7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(role='system', content='You can bring insights about a game dataset based on users questions'),\n",
       " UserMessage(role='user', content='Give me score statistics grouped by Platform and a histogram bucketed by 5.'),\n",
       " AIMessage(role='assistant', content=None, tool_calls=[ChatCompletionMessageToolCall(id='call_hgmCnDp8wf1CQIb3nqeDkIFn', function=Function(arguments='{\"group_by\":\"Platform\",\"bucket_size\":5}', name='get_game_stats'), type='function')]),\n",
       " ToolMessage(role='tool', content='{\"count\": 10, \"score\": {\"avg\": 91.5, \"median\": 92.0, \"min\": 85, \"max\": 98, \"stdev\": 4.588027898781785}, \"distribution\": {\"Switch\": {\"count\": 4, \"avg\": 93.25}, \"GameCube\": {\"count\": 1, \"avg\": 97.0}, \"Wii\": {\"count\": 2, \"avg\": 90.0}, \"3DS\": {\"count\": 2, \"avg\": 90.0}, \"Wii U\": {\"count\": 1, \"avg\": 85.0}}, \"score_histogram\": {\"85-89\": 4, \"90-94\": 3, \"95-99\": 3}}', tool_call_id='call_hgmCnDp8wf1CQIb3nqeDkIFn', name='get_game_stats'),\n",
       " AIMessage(role='assistant', content='Here are the score statistics grouped by Platform, along with a histogram bucketed by 5:\\n\\n### Score Statistics\\n- **Total Games Count**: 10\\n- **Average Score**: 91.5\\n- **Median Score**: 92.0\\n- **Minimum Score**: 85\\n- **Maximum Score**: 98\\n- **Standard Deviation**: 4.59\\n\\n### Score Distribution by Platform\\n- **Switch**: \\n  - Count: 4\\n  - Average Score: 93.25\\n- **GameCube**: \\n  - Count: 1\\n  - Average Score: 97.0\\n- **Wii**: \\n  - Count: 2\\n  - Average Score: 90.0\\n- **3DS**: \\n  - Count: 2\\n  - Average Score: 90.0\\n- **Wii U**: \\n  - Count: 1\\n  - Average Score: 85.0\\n\\n### Score Histogram\\n- **85-89**: 4 games\\n- **90-94**: 3 games\\n- **95-99**: 3 games\\n\\nIf you have any further questions or need more insights, feel free to ask!', tool_calls=None)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Request score statistics grouped by Platform with histogram bucket size 5\n",
    "initial_state_3: AgentState = {\n",
    "    \"user_query\": \"Give me score statistics grouped by Platform and a histogram bucketed by 5.\",\n",
    "    \"instructions\": \"You can bring insights about a game dataset based on users questions\",\n",
    "    \"messages\": [],\n",
    "}\n",
    "run_object_3 = workflow.run(initial_state_3)\n",
    "run_object_3.get_final_state()[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f4f2569-a593-46d0-85fa-f95b8f727c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM:\n",
      "'You can bring insights about a game dataset based on users questions'\n",
      "--------------------------------------------------------------------------------\n",
      "USER:\n",
      "'Give me score statistics grouped by Platform and a histogram bucketed by 5.'\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT: [tool_calls]\n",
      "  -> call_id=call_hgmCnDp8wf1CQIb3nqeDkIFn func=get_game_stats args={\"group_by\":\"Platform\",\"bucket_size\":5}\n",
      "--------------------------------------------------------------------------------\n",
      "TOOL[get_game_stats]:\n",
      "{'count': 10,\n",
      " 'distribution': {'3DS': {'avg': 90.0, 'count': 2},\n",
      "                  'GameCube': {'avg': 97.0, 'count': 1},\n",
      "                  'Switch': {'avg': 93.25, 'count': 4},\n",
      "                  'Wii': {'avg': 90.0, 'count': 2},\n",
      "                  'Wii U': {'avg': 85.0, 'count': 1}},\n",
      " 'score': {'avg': 91.5, 'max': 98, 'median': 92.0, 'min': 85, 'stdev': 4.588027898781785},\n",
      " 'score_histogram': {'85-89': 4, '90-94': 3, '95-99': 3}}\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT:\n",
      "('Here are the score statistics grouped by Platform, along with a histogram bucketed by 5:\\n'\n",
      " '\\n'\n",
      " '### Score Statistics\\n'\n",
      " '- **Total Games Count**: 10\\n'\n",
      " '- **Average Score**: 91.5\\n'\n",
      " '- **Median Score**: 92.0\\n'\n",
      " '- **Minimum Score**: 85\\n'\n",
      " '- **Maximum Score**: 98\\n'\n",
      " '- **Standard Deviation**: 4.59\\n'\n",
      " '\\n'\n",
      " '### Score Distribution by Platform\\n'\n",
      " '- **Switch**: \\n'\n",
      " '  - Count: 4\\n'\n",
      " '  - Average Score: 93.25\\n'\n",
      " '- **GameCube**: \\n'\n",
      " '  - Count: 1\\n'\n",
      " '  - Average Score: 97.0\\n'\n",
      " '- **Wii**: \\n'\n",
      " '  - Count: 2\\n'\n",
      " '  - Average Score: 90.0\\n'\n",
      " '- **3DS**: \\n'\n",
      " '  - Count: 2\\n'\n",
      " '  - Average Score: 90.0\\n'\n",
      " '- **Wii U**: \\n'\n",
      " '  - Count: 1\\n'\n",
      " '  - Average Score: 85.0\\n'\n",
      " '\\n'\n",
      " '### Score Histogram\\n'\n",
      " '- **85-89**: 4 games\\n'\n",
      " '- **90-94**: 3 games\\n'\n",
      " '- **95-99**: 3 games\\n'\n",
      " '\\n'\n",
      " 'If you have any further questions or need more insights, feel free to ask!')\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pretty_print_messages(run_object_3.get_final_state()[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22e0dfa1-a817-46a3-a4e3-b69d420e21ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def extract_histogram(messages):\n",
    "    for m in messages:\n",
    "        if getattr(m, \"name\", \"\") == \"get_game_stats\":\n",
    "            try:\n",
    "                payload = json.loads(getattr(m, \"content\", \"\"))\n",
    "                return payload.get(\"score_histogram\")\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "hist = extract_histogram(run_object_3.get_final_state()[\"messages\"])\n",
    "if hist is None:\n",
    "    print(\"No score_histogram found in tool outputs.\")\n",
    "else:\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        labels = list(hist.keys())\n",
    "        values = [hist[k] for k in labels]\n",
    "\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.bar(labels, values)\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(\"Score Histogram (bucket size 5)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Matplotlib not available; showing ASCII chart instead.\\n\")\n",
    "        for k, v in hist.items():\n",
    "            print(f\"{k:>10} | {'#' * int(v)} ({v})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89629e4a",
   "metadata": {},
   "source": [
    "## Optional \n",
    "\n",
    "Create an Agent class to encapsulate State Machine logic. Then try adding more tools, and experiment with different user queries to see how the workflow adapts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2e7d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement your Agent\n",
    "# Develope the following methods: _prepare_messages_step, _llm_step, _tool_step, _create_state_machine\n",
    "class Agent:\n",
    "    def __init__(self, \n",
    "                 model_name: str,\n",
    "                 instructions: str, \n",
    "                 tools: List[Tool] = None,\n",
    "                 temperature: float = 0.7):\n",
    "        \"\"\"\n",
    "        Initialize an Agent instance\n",
    "        \n",
    "        Args:\n",
    "            model_name: Name/identifier of the LLM model to use\n",
    "            instructions: System instructions for the agent\n",
    "            tools: Optional list of tools available to the agent\n",
    "            temperature: Temperature parameter for LLM (default: 0.7)\n",
    "        \"\"\"\n",
    "        self.instructions = instructions\n",
    "        self.tools = tools if tools else []\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "                \n",
    "        # Initialize state machine\n",
    "        self.workflow = self._create_state_machine()\n",
    "\n",
    "    def _prepare_messages_step(self, state: AgentState) -> AgentState:\n",
    "        messages = [\n",
    "            SystemMessage(content=state[\"instructions\"]),\n",
    "            UserMessage(content=state[\"user_query\"])\n",
    "        ]\n",
    "        return { \"messages\": messages }\n",
    "\n",
    "    def _llm_step(self, state: AgentState) -> AgentState:\n",
    "        llm = LLM(\n",
    "            model=self.model_name,\n",
    "            temperature=self.temperature,\n",
    "            tools=self.tools\n",
    "        )\n",
    "\n",
    "        response = llm.invoke(state[\"messages\"])\n",
    "        tool_calls = response.tool_calls if response.tool_calls else None\n",
    "\n",
    "        ai_message = AIMessage(content=response.content, tool_calls=tool_calls)\n",
    "        \n",
    "        return {\n",
    "            \"messages\": state[\"messages\"] + [ai_message],\n",
    "            \"current_tool_calls\": tool_calls\n",
    "        }\n",
    "\n",
    "    def _tool_step(self, state: AgentState) -> AgentState:\n",
    "        tool_calls = state[\"current_tool_calls\"] or []\n",
    "        tool_messages = []\n",
    "        \n",
    "        for call in tool_calls:\n",
    "            function_name = call.function.name\n",
    "            function_args = json.loads(call.function.arguments)\n",
    "            tool_call_id = call.idx\n",
    "            tool = next((t for t in self.tools if t.name == function_name), None)\n",
    "            if tool:\n",
    "                result = tool(**function_args)\n",
    "                tool_messages.append(\n",
    "                    ToolMessage(\n",
    "                        content=json.dumps(result), \n",
    "                        tool_call_id=tool_call_id, \n",
    "                        name=function_name, \n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        return {\n",
    "            \"messages\": state[\"messages\"] + tool_messages,\n",
    "            \"current_tool_calls\": None\n",
    "        }\n",
    "\n",
    "    def _create_state_machine(self) -> StateMachine[AgentState]:\n",
    "        workflow = StateMachine(AgentState)\n",
    "        \n",
    "        entry = EntryPoint[AgentState]()\n",
    "        message_prep = Step[AgentState](\"message_prep\", prepare_messages_step)\n",
    "        llm_processor = Step[AgentState](\"llm_processor\", llm_step)\n",
    "        tool_executor = Step[AgentState](\"tool_executor\", tool_step)\n",
    "        termination = Termination[AgentState]()\n",
    "         \n",
    "        workflow.add_steps([\n",
    "            entry,\n",
    "            message_prep,\n",
    "            llm_processor,\n",
    "            tool_executor,\n",
    "            termination\n",
    "        ])\n",
    "        \n",
    "        workflow.connect(entry, message_prep)\n",
    "        workflow.connect(message_prep, llm_processor)\n",
    "        \n",
    "        def check_tool_calls(state: AgentState) -> Union[Step[AgentState], str]:\n",
    "            \"\"\"Transition logic: Check if there are tool calls\"\"\"\n",
    "            if state.get(\"current_tool_calls\"):\n",
    "                return tool_executor\n",
    "            return termination\n",
    "        \n",
    "        # Routing: If tool calls -> tool_executor\n",
    "        workflow.connect(\n",
    "            source=llm_processor, \n",
    "            targets=[tool_executor, termination], \n",
    "            condition=check_tool_calls\n",
    "        )\n",
    "        \n",
    "        # Looping: Go back to llm after tool execution\n",
    "        workflow.connect(\n",
    "            source=tool_executor, \n",
    "            targets=llm_processor\n",
    "        )\n",
    "\n",
    "        return workflow\n",
    "\n",
    "    def invoke(self, query: str) -> Run:\n",
    "        \"\"\"\n",
    "        Run the agent on a query\n",
    "        \n",
    "        Args:\n",
    "            query: The user's query to process\n",
    "            \n",
    "        Returns:\n",
    "            The final run object after processing\n",
    "        \"\"\"\n",
    "\n",
    "        initial_state: AgentState = {\n",
    "            \"user_query\": query,\n",
    "            \"instructions\": self.instructions,\n",
    "            \"messages\": [],\n",
    "        }\n",
    "\n",
    "        run_object = self.workflow.run(initial_state)\n",
    "\n",
    "        return run_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dceddaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional\n",
    "import json\n",
    "from lib.tooling import tool\n",
    "\n",
    "@tool\n",
    "def get_games_by_platform(platform: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Return all games for a given platform (case-insensitive).\"\"\"\n",
    "    p = platform.strip().lower()\n",
    "    return [row for row in GAMES_DATA if row.get(\"Platform\",\"\").lower() == p]\n",
    "\n",
    "@tool\n",
    "def search_games(name_contains: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Return games whose name contains the given substring (case-insensitive).\"\"\"\n",
    "    q = name_contains.strip().lower()\n",
    "    return [row for row in GAMES_DATA if q in row.get(\"Game\",\"\").lower()]\n",
    "\n",
    "@tool\n",
    "def compare_two_games(game_a: str, game_b: str) -> Dict[str, Any]:\n",
    "    \"\"\"Compare two games by exact name and report which has higher score (or tie).\"\"\"\n",
    "    def _find(name: str) -> Optional[Dict[str, Any]]:\n",
    "        for row in GAMES_DATA:\n",
    "            if row.get(\"Game\",\"\") == name:\n",
    "                return row\n",
    "        return None\n",
    "\n",
    "    a = _find(game_a)\n",
    "    b = _find(game_b)\n",
    "    if not a or not b:\n",
    "        return {\"error\": \"One or both games not found\", \"a\": a, \"b\": b}\n",
    "\n",
    "    winner = \"tie\"\n",
    "    if a[\"Score\"] > b[\"Score\"]:\n",
    "        winner = game_a\n",
    "    elif b[\"Score\"] > a[\"Score\"]:\n",
    "        winner = game_b\n",
    "\n",
    "    return {\"a\": a, \"b\": b, \"winner\": winner}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66bbe286-ddef-4a23-82a3-092305e5dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSIGHTS_INSTRUCTIONS = (\n",
    "    \"You analyze a small games dataset. \"\n",
    "    \"Use tools to fetch data; then answer concisely with bullet points.\"\n",
    ")\n",
    "\n",
    "KID_FRIENDLY_INSTRUCTIONS = (\n",
    "    \"Explain to a 10-year-old. Keep answers short and simple. \"\n",
    "    \"If you use tools, summarize results clearly.\"\n",
    ")\n",
    "\n",
    "AUDITOR_INSTRUCTIONS = (\n",
    "    \"Verify claims strictly against tool outputs. \"\n",
    "    \"If data is insufficient, say so explicitly. Be precise.\"\n",
    ")\n",
    "\n",
    "tools_for_agent = [get_games, get_game_stats, get_games_by_platform, search_games, compare_two_games]\n",
    "\n",
    "insights_agent = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    instructions=INSIGHTS_INSTRUCTIONS,\n",
    "    tools=tools_for_agent,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "kid_agent = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    instructions=KID_FRIENDLY_INSTRUCTIONS,\n",
    "    tools=tools_for_agent,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "auditor_agent = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    instructions=AUDITOR_INSTRUCTIONS,\n",
    "    tools=tools_for_agent,\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b32e1d72-6834-4ede-8e6f-e1f3b8386ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dump(messages):\n",
    "    try:\n",
    "        pretty_print_messages(messages)\n",
    "    except NameError:\n",
    "        for m in messages:\n",
    "            role = getattr(m, \"role\", type(m).__name__)\n",
    "            print(role.upper(), \"=>\", getattr(m, \"content\", None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7698c92e-acf9-4e62-afda-e979e8cb71dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Insights Agent: Top 2 Switch games ===\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "SYSTEM:\n",
      "('You analyze a small games dataset. Use tools to fetch data; then answer concisely with bullet '\n",
      " 'points.')\n",
      "--------------------------------------------------------------------------------\n",
      "USER:\n",
      "'What are the top 2 games for the Switch and their scores?'\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT: [tool_calls]\n",
      "  -> call_id=call_IE6mguBpyIT7WijCtlX3y8YQ func=get_games args={\"num_games\": 2, \"top\": true}\n",
      "  -> call_id=call_S2fANw8vLyzMiAbkeTZozA67 func=get_game_stats args={\"group_by\": \"Platform\"}\n",
      "--------------------------------------------------------------------------------\n",
      "TOOL[get_games]:\n",
      "[{'Game': 'The Legend of Zelda: Breath of the Wild', 'Platform': 'Switch', 'Score': 98},\n",
      " {'Game': 'Super Mario Odyssey', 'Platform': 'Switch', 'Score': 97}]\n",
      "--------------------------------------------------------------------------------\n",
      "TOOL[get_game_stats]:\n",
      "{'count': 10,\n",
      " 'distribution': {'3DS': {'avg': 90.0, 'count': 2},\n",
      "                  'GameCube': {'avg': 97.0, 'count': 1},\n",
      "                  'Switch': {'avg': 93.25, 'count': 4},\n",
      "                  'Wii': {'avg': 90.0, 'count': 2},\n",
      "                  'Wii U': {'avg': 85.0, 'count': 1}},\n",
      " 'score': {'avg': 91.5, 'max': 98, 'median': 92.0, 'min': 85, 'stdev': 4.588027898781785},\n",
      " 'score_histogram': None}\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT:\n",
      "('- **Top 2 Games for the Switch:**\\n'\n",
      " '  - **The Legend of Zelda: Breath of the Wild** - Score: 98\\n'\n",
      " '  - **Super Mario Odyssey** - Score: 97\\n'\n",
      " '\\n'\n",
      " '- **Additional Stats:**\\n'\n",
      " '  - Average Score for Switch games: 93.25\\n'\n",
      " '  - Total Switch games analyzed: 4')\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Insights Agent: Top 2 Switch games ===\")\n",
    "run1 = insights_agent.invoke(\"What are the top 2 games for the Switch and their scores?\")\n",
    "_dump(run1.get_final_state()[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c5f4b44-0f92-4f25-a0cc-ca3f197618d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Kid Agent: Mario games and are they good? ===\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "SYSTEM:\n",
      "('Explain to a 10-year-old. Keep answers short and simple. If you use tools, summarize results '\n",
      " 'clearly.')\n",
      "--------------------------------------------------------------------------------\n",
      "USER:\n",
      "\"Find any games with 'Mario' and tell me if they're good.\"\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT: [tool_calls]\n",
      "  -> call_id=call_2WtgQ3nm8RjJp4svCGpdKzNX func=get_games args={\"num_games\":5,\"top\":true}\n",
      "--------------------------------------------------------------------------------\n",
      "TOOL[get_games]:\n",
      "[{'Game': 'The Legend of Zelda: Breath of the Wild', 'Platform': 'Switch', 'Score': 98},\n",
      " {'Game': 'Super Mario Odyssey', 'Platform': 'Switch', 'Score': 97},\n",
      " {'Game': 'Metroid Prime', 'Platform': 'GameCube', 'Score': 97},\n",
      " {'Game': 'Super Smash Bros. Brawl', 'Platform': 'Wii', 'Score': 93},\n",
      " {'Game': 'Mario Kart 8 Deluxe', 'Platform': 'Switch', 'Score': 92}]\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT:\n",
      "(\"I found some games with 'Mario' in them:\\n\"\n",
      " '\\n'\n",
      " '1. **Super Mario Odyssey** - Score: 97\\n'\n",
      " '2. **Mario Kart 8 Deluxe** - Score: 92\\n'\n",
      " '\\n'\n",
      " 'Both of these games are really good because they have high scores!')\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Kid Agent: Mario games and are they good? ===\")\n",
    "run2 = kid_agent.invoke(\"Find any games with 'Mario' and tell me if they're good.\")\n",
    "_dump(run2.get_final_state()[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a4f41b9-fe5a-4d73-8782-a7348b25c724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Auditor Agent: Is Pikmin 3 better than Luigi's Mansion 3? ===\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "SYSTEM:\n",
      "('Verify claims strictly against tool outputs. If data is insufficient, say so explicitly. Be '\n",
      " 'precise.')\n",
      "--------------------------------------------------------------------------------\n",
      "USER:\n",
      "\"Is 'Pikmin 3' better than 'Luigi's Mansion 3'? Check the scores.\"\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT: [tool_calls]\n",
      "  -> call_id=call_KCfMhC5JfD3S5meDrShQKK2V func=get_games args={\"num_games\": 1, \"top\": true}\n",
      "  -> call_id=call_hRkk8KX7XO8dbk5KGZcKqD1W func=get_games args={\"num_games\": 1, \"top\": false}\n",
      "--------------------------------------------------------------------------------\n",
      "TOOL[get_games]:\n",
      "[{'Game': 'The Legend of Zelda: Breath of the Wild', 'Platform': 'Switch', 'Score': 98}]\n",
      "--------------------------------------------------------------------------------\n",
      "TOOL[get_games]:\n",
      "[{'Game': 'Pikmin 3', 'Platform': 'Wii U', 'Score': 85}]\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT: [tool_calls]\n",
      "  -> call_id=call_sKGL1ym6KuxhY5BX5bOM9isQ func=get_games args={\"num_games\":5,\"top\":true}\n",
      "--------------------------------------------------------------------------------\n",
      "TOOL[get_games]:\n",
      "[{'Game': 'The Legend of Zelda: Breath of the Wild', 'Platform': 'Switch', 'Score': 98},\n",
      " {'Game': 'Super Mario Odyssey', 'Platform': 'Switch', 'Score': 97},\n",
      " {'Game': 'Metroid Prime', 'Platform': 'GameCube', 'Score': 97},\n",
      " {'Game': 'Super Smash Bros. Brawl', 'Platform': 'Wii', 'Score': 93},\n",
      " {'Game': 'Mario Kart 8 Deluxe', 'Platform': 'Switch', 'Score': 92}]\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT: [tool_calls]\n",
      "  -> call_id=call_JP3DBSUemZPQDqAwhAnFxUZ5 func=get_games args={\"num_games\":5,\"top\":false}\n",
      "--------------------------------------------------------------------------------\n",
      "TOOL[get_games]:\n",
      "[{'Game': 'Pikmin 3', 'Platform': 'Wii U', 'Score': 85},\n",
      " {'Game': \"Luigi's Mansion 3\", 'Platform': 'Switch', 'Score': 86},\n",
      " {'Game': 'Donkey Kong Country Returns', 'Platform': 'Wii', 'Score': 87},\n",
      " {'Game': 'Animal Crossing: New Leaf', 'Platform': '3DS', 'Score': 88},\n",
      " {'Game': 'Mario Kart 8 Deluxe', 'Platform': 'Switch', 'Score': 92}]\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT:\n",
      "('The scores for the games are as follows:\\n'\n",
      " '\\n'\n",
      " '- **Pikmin 3**: 85\\n'\n",
      " \"- **Luigi's Mansion 3**: 86\\n\"\n",
      " '\\n'\n",
      " \"Based on the scores, **Luigi's Mansion 3** is rated higher than **Pikmin 3**.\")\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Auditor Agent: Is Pikmin 3 better than Luigi's Mansion 3? ===\")\n",
    "run3 = auditor_agent.invoke(\"Is 'Pikmin 3' better than 'Luigi's Mansion 3'? Check the scores.\")\n",
    "_dump(run3.get_final_state()[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d77a52c-1ce6-4176-a5bb-255306e41cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
